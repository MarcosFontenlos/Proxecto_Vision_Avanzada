
# ğŸ¤– Proxecto VisiÃ³n Artificial Avanzada

Este proyecto desarrolla un sistema de percepciÃ³n visual modular sobre **ROS 2**, capaz de detectar personas y gestos mediante visiÃ³n artificial, y controlar el movimiento de un robot mÃ³vil (Kompai) en funciÃ³n de la informaciÃ³n captada.

## ğŸ§  Arquitectura del Sistema

El sistema estÃ¡ compuesto por tres nodos principales:

- ğŸŸ¡ **`yolo_detector`**  
  Detecta personas y objetos utilizando **YOLOv8**. Publica las detecciones en el topic `/detecciones_yolo`.

- ğŸŸ¢ **`hand_gesture`**  
  Detecta gestos de mano a partir de la imagen de la cÃ¡mara. Publica los resultados en `/gestos_mano`.

- ğŸ”µ **`robot_controller`**  
  Recibe los datos anteriores, decide la acciÃ³n a realizar, y envÃ­a comandos al robot **Kompai** vÃ­a HTTP o sockets.

## ğŸ“ Estructura del Workspace

```
vision_ws/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ yolo_detector/        # Nodo YOLOv8
â”‚   â”œâ”€â”€ hand_gesture/         # Nodo de gestos de mano
â”‚   â””â”€â”€ robot_controller/     # Nodo de control (por implementar)
â”œâ”€â”€ yolov8n.pt                # Modelo preentrenado YOLOv8 Nano
â”œâ”€â”€ install/
â”œâ”€â”€ build/
â””â”€â”€ log/
```

## âš™ï¸ InstalaciÃ³n

1. Clonar el repositorio:

```bash
git clone https://github.com/MarcosFontenlos/Proxecto_Vision_Avanzada.git
cd Proxecto_Vision_Avanzada/vision_ws
```

2. Instalar dependencias (fuera del entorno virtual si usas ROS puro):

```bash
pip3 install ultralytics opencv-python
```

3. Compilar el workspace:

```bash
colcon build
source install/setup.bash
```

## â–¶ï¸ EjecuciÃ³n

### Nodo YOLO

```bash
ros2 run yolo_detector yolo_node
```

### Nodo Gestos (cuando estÃ© implementado)

```bash
ros2 run hand_gesture gesture_node
```

### Nodo Controlador del Robot (futuro)

```bash
ros2 run robot_controller controller_node
```

## ğŸ•¹ ConexiÃ³n y Movimiento
## ğŸ”Œ ConexiÃ³n:
 
- Pulsar el botÃ³n en la parte trasera del mando.  
- Pulsar el botÃ³n **Start**.
- EncenderÃ¡ la luz. 

## ğŸ§­ Movimiento:

- Pulsar el **gatillo izquierdo**.  
- Pulsar el **botÃ³n A**.  
- Usar el **joystick izquierdo** para moverse.
    
## ğŸ“¡ Topics utilizados

- `/detecciones_yolo` â€“ Detecciones de objetos con YOLO.
- `/gestos_mano` â€“ Gestos detectados con visiÃ³n.
- `/comando_robot` â€“ Comandos al robot segÃºn percepciÃ³n.

## ğŸ›  TecnologÃ­as

- ROS 2 Humble
- Python 3.10
- YOLOv8 (Ultralytics)
- OpenCV
- ComunicaciÃ³n HTTP/TCP con robot Kompai

## ğŸ‘¥ Autores

- **Marcos Fontenlos**  
  [@MarcosFontenlos](https://github.com/MarcosFontenlos)

- **Alejandro Solar**  
  [@AlejandroSIRob](https://github.com/AlejandroSIRob)
